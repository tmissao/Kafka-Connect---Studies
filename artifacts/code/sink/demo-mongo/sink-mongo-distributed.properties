# Basic configuration for our connector
name=sink-mongo-customer-distributed
connector.class=com.mongodb.kafka.connect.MongoSinkConnector
# We could parallel this task to increase performance
tasks.max=1

# Topic to be consumed
topics=dbserver1.inventory.customers,dbserver1.inventory.products,dbserver1.inventory.addresses
# topics.regex=dbserver1\\.\\w+\\.\\w+$

# Transformations
transforms=unwrap,renameField
transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState
# Include debezium informations about table and database that will be used by
# Mongo connector to decide where to save the data
transforms.unwrap.add.fields=table,db
transforms.unwrap.delete.handling.mode=rewrite
# Mongo Connector needs to generate a _id, so in this case we are renaming
# the id to _id in order to mongo use it
transforms.renameField.type=org.apache.kafka.connect.transforms.ReplaceField$Key
transforms.renameField.renames=id:_id

# Mongo configuration
connection.uri=mongodb://root:mongo@mongo:27017
database=default
collection=default
# Configures mongo to router data based on record data information
namespace.mapper=com.mongodb.kafka.connect.sink.namespace.mapping.FieldPathNamespaceMapper
# Configures mongo to decide the database where data will be saved based on __db value of the record
namespace.mapper.value.database.field=__db
# Configures mongo to decide the database where data will be saved based on __table value of the record
namespace.mapper.value.collection.field=__table
# Configures mongo to use the _id base on the _id of the record key
document.id.strategy=com.mongodb.kafka.connect.sink.processor.id.strategy.ProvidedInKeyStrategy
# Configures mongo to realize a post processor of the message using the BlockListValue stragegy
post.processor.chain=com.mongodb.kafka.connect.sink.processor.BlockListValueProjector
value.projection.type=BlockList
# Prevents the values __db and __table from mongo to be saved on collection 
value.projection.list=__db,__table
